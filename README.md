ğŸ›¡ï¸ Fraud Detection System
ğŸ“Œ Project Overview

This project focuses on building a machine learningâ€“based fraud detection system using transactional data. The goal is to accurately identify fraudulent transactions while addressing key challenges such as extreme class imbalance, high false-negative cost, and model interpretability.

The project is implemented using modular, reusable, and scalable components suitable for both credit card and e-commerce fraud datasets.
#----------------------------------------------------------------------

ğŸ›¡ï¸ Fraud Detection System
ğŸ“Œ Project Overview

This project focuses on building a machine learningâ€“based fraud detection system using transactional data. The goal is to accurately identify fraudulent transactions while addressing key challenges such as extreme class imbalance, high false-negative cost, and model interpretability.

The project is implemented using modular, reusable, and scalable components suitable for both credit card and e-commerce fraud datasets.

#-------------------------------------------------------------------------------------------------------

ğŸ“‚ Project Structure
Fraud-Detecton-for-ecommerce/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original datasets
â”‚ â”œâ”€â”€ processed/ # Train-test splits and cleaned data
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA.ipynb # Exploratory Data Analysis
â”‚ â”œâ”€â”€ FeatureEngineering.ipynb
â”‚ â”œâ”€â”€ Modeling.ipynb # Model training & evaluation
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ creditcard_transformer.py # Data preprocessing & SMOTE
â”‚ â”œâ”€â”€ model_trainer.py # Model training & evaluation
â”‚
â”œâ”€â”€
â”‚ # EDA plots & visualizations
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

#-----------------------------------------------------------------------------------------------------------------
ğŸ“Š Datasets Used

Credit Card Dataset

Target column: Class

E-commerce Fraud Dataset

Target column: class

Both datasets exhibit severe class imbalance, which is a central challenge addressed in this project.

ğŸ” Exploratory Data Analysis (EDA)

Key insights from EDA include:

The vast majority of transactions are low-value

Fraudulent transactions tend to cluster in lower transaction amounts

Transactions are concentrated within a short time window

Fraud patterns are highly skewed, justifying imbalance-aware modeling

ğŸ“Œ Business implication:
Missing fraudulent transactions (false negatives) has a much higher cost than false positives, motivating the use of recall-sensitive metrics.

#---------------------------------------------------------------------------------------------------------------------------------------

âš™ï¸ Data Preprocessing & Feature Engineering

Checked for missing values and data consistency

Standardized numerical features where required

Created time-based and behavior-related features

Applied SMOTE only on the training set to avoid data leakage

Used stratified splitting to preserve class distribution

âš–ï¸ Handling Class Imbalance

Class imbalance was addressed using:

SMOTE (Synthetic Minority Over-sampling Technique) for training data

class_weight="balanced" for Logistic Regression

Evaluation metrics robust to imbalance (PR-AUC, F1)

ğŸ“Œ Why this matters:
Imbalanced data can lead to models that appear accurate but completely fail to detect fraud

Imbalanced data can lead to models that appear accurate but completely fail to detect fraud.

ğŸ¤– Model Building
1ï¸âƒ£ Baseline Model â€” Logistic Regression

Interpretable and fast

Serves as a performance benchmark

Uses class-weight balancing

2ï¸âƒ£ Ensemble Model â€” Random Forest

Captures non-linear relationships

More robust to noise and feature interactions

Hyperparameter tuning applied using RandomizedSearchCV

ğŸ“ˆ Model Evaluation Metrics

The following metrics are used due to the imbalanced nature of fraud data:

PR-AUC (Precision-Recall AUC) â€“ primary metric

F1-Score â€“ balance between precision and recall

Confusion Matrix â€“ error analysis

ğŸ” Cross-Validation

Stratified K-Fold (k=5) used

Reports mean and standard deviation for:

PR-AUC

F1-Score

ğŸ“Œ This ensures performance stability and reduces overfitting risk.

ğŸ§ª Model Comparison & Selection

Models are compared side-by-side based on:

PR-AUC performance

F1-Score

Interpretability vs complexity trade-off

The selected model balances fraud detection performance and operational interpretability.

ğŸ§  Key Learnings

Accuracy is misleading for fraud detection

PR-AUC is more informative than ROC-AUC

Proper handling of class imbalance is critical

Modular code greatly improves reusability and debugging

Cross-validation is essential for reliable evaluation

ğŸš§ Current Limitations

Feature importance analysis can be expanded

Explainability tools (e.g., SHAP) not yet integrated

Pipeline-based deployment not yet implemented

ğŸš€ Next Steps

Integrate preprocessing and modeling into a unified pipeline

Add model explainability (SHAP)

Improve error handling and logging

Enhance documentation and unit testing

Explore gradient boosting models (XGBoost / LightGBM)

ğŸ› ï¸ Technologies Used

Python

NumPy, Pandas

Scikit-learn

Imbalanced-learn

Matplotlib / Seaborn
